pdf("plots.pdf")#
par(mfrow=c(1,2))#
#
plot(e_1, type="l", xlab="# predictors in model")#
lines(e.b_1, type="l")#
#
plot(e_2, type="l", xlab="# predictors in model")#
lines(e.b_2, type="l")#
dev.off()
e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)
plot(e_1)
e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)
e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)
e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)
pdf("plots.pdf")#
par(mfrow=c(1,2))#
#
plot(e_1, type="l", xlab="# predictors in model")#
lines(e.b_1, type="l")#
#
plot(e_2, type="l", xlab="# predictors in model")#
lines(e.b_2, type="l")#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model")#
lines(e.b_1, type="l")#
#
plot(e_2, type="l", xlab="# predictors in model")#
lines(e.b_2, type="l")#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="error")#
lines(e.b_1, type="l")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="error")#
lines(e.b_2, type="l")#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text=(25, e_1[25], labels="not bagged")#
text=(25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text=(25, e_2[25], labels="not bagged")#
text=(25, e.b_2[25], labels="bagged")#
#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text=(x=25, y=e_1[25], labels="not bagged")#
text=(x=25, y=e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text=(x=25, y=e_2[25], labels="not bagged")#
text=(x=25, y=e.b_2[25], labels="bagged")#
#
dev.off()
text=(x=25, e.b_2[25], labels="bagged")
text=(x=25 e.b_2[25], labels="bagged")
text=(x=25, e.b_2[25], labels="bagged")
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
#### STAT 239 HW 4#
#
#### DATA ANALYSIS I: BAGGING LINEAR PREDICTORS#
#
# 1)#
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 3#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, M, p)#
err_2 = matrix(NA, M, p)#
err.bag_1 = matrix(NA, M, p)#
err.bag_2 = matrix(NA, M, p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e.b_1 = rep(NA, p)#
e.b_2 = rep(NA, p)#
#
for(m in 1:M)#
{#
#
X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
#
Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
#
Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
#
# signal to noise ratio#
s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
#
# 2)#
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
errors_1 = rep(0, p)#
errors_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	errors_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	errors_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = errors_1#
err_2[m,] = errors_2#
# 3, 4, 5)#
B = 50#
errors_1b = matrix(ncol = p, nrow = B, 0)#
errors_2b = matrix(ncol = p, nrow = B, 0)#
error_1b = rep(0, p)#
error_2b = rep(0, p)#
#
for(b in 1:B)#
{#
	bootstraps = sample(nrow(Train_1), nrow(Train_1), replace=TRUE)#
	model_1= regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2= regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		errors_1b[b,k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		errors_2b[b,k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
}#
#
for(k in 1:p)#
{	#
	error_1b[k] = mean(errors_1b[,k])#
	error_2b[k] = mean(errors_2b[,k])#
}#
#
err.bag_1[m,] = error_1b#
err.bag_2[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e.b_1[k] = mean(err.bag_1[,k])#
	e.b_2[k] = mean(err.bag_2[,k])#
}#
#
e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)#
#
e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)#
#
e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)#
#
e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)#
#
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
#### STAT 239 HW 4#
#
#### DATA ANALYSIS I: BAGGING LINEAR PREDICTORS#
#
# 1)#
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 3#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, M, p)#
err_2 = matrix(NA, M, p)#
err.bag_1 = matrix(NA, M, p)#
err.bag_2 = matrix(NA, M, p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e.b_1 = rep(NA, p)#
e.b_2 = rep(NA, p)#
#
for(m in 1:M)#
{#
#
X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
#
Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
#
Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
#
# signal to noise ratio#
s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
#
# 2)#
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
errors_1 = rep(0, p)#
errors_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	errors_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	errors_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = errors_1#
err_2[m,] = errors_2#
# 3, 4, 5)#
B = 50#
errors_1b = matrix(ncol = p, nrow = B, 0)#
errors_2b = matrix(ncol = p, nrow = B, 0)#
error_1b = rep(0, p)#
error_2b = rep(0, p)#
#
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train_1), nrow(X_Train_1), replace=TRUE)#
	model_1= regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2= regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		errors_1b[b,k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		errors_2b[b,k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
}#
#
for(k in 1:p)#
{	#
	error_1b[k] = mean(errors_1b[,k])#
	error_2b[k] = mean(errors_2b[,k])#
}#
#
err.bag_1[m,] = error_1b#
err.bag_2[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e.b_1[k] = mean(err.bag_1[,k])#
	e.b_2[k] = mean(err.bag_2[,k])#
}#
#
# e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)#
#
# e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)#
#
# e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)#
#
# e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)#
#
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)#
#
e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)#
#
e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)#
#
e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)
pdf("plots2.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 3#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, M, p)#
err_2 = matrix(NA, M, p)#
err.bag_1 = matrix(NA, M, p)#
err.bag_2 = matrix(NA, M, p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e.b_1 = rep(NA, p)#
e.b_2 = rep(NA, p)#
#
for(m in 1:M)#
{#
#
X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
#
Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
#
Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
#
# signal to noise ratio#
s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
#
# 2)#
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
errors_1 = rep(0, p)#
errors_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	errors_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	errors_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = errors_1#
err_2[m,] = errors_2#
# 3, 4, 5)#
B = 50#
errors_1b = matrix(ncol = p, nrow = B, 0)#
errors_2b = matrix(ncol = p, nrow = B, 0)#
error_1b = rep(0, p)#
error_2b = rep(0, p)#
#
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train_1), nrow(X_Train_1), replace=TRUE)#
	model_1= regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2= regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		errors_1b[b,k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		errors_2b[b,k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
}#
#
for(k in 1:p)#
{	#
	error_1b[k] = mean(errors_1b[,k])#
	error_2b[k] = mean(errors_2b[,k])#
}#
#
err.bag_1[m,] = error_1b#
err.bag_2[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e.b_1[k] = mean(err.bag_1[,k])#
	e.b_2[k] = mean(err.bag_2[,k])#
}
#### STAT 239 HW 4#
#
#### DATA ANALYSIS I: BAGGING LINEAR PREDICTORS#
#
# 1)#
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 3#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, M, p)#
err_2 = matrix(NA, M, p)#
err.bag_1 = matrix(NA, M, p)#
err.bag_2 = matrix(NA, M, p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e.b_1 = rep(NA, p)#
e.b_2 = rep(NA, p)#
#
for(m in 1:M)#
{#
#
X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
#
Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
#
Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
#
# signal to noise ratio#
s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
#
# 2)#
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
errors_1 = rep(0, p)#
errors_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	errors_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	errors_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = errors_1#
err_2[m,] = errors_2#
# 3, 4, 5)#
B = 50#
errors_1b = matrix(ncol = p, nrow = B, 0)#
errors_2b = matrix(ncol = p, nrow = B, 0)#
error_1b = rep(0, p)#
error_2b = rep(0, p)#
#
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
	model_1= regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2= regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		errors_1b[b,k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		errors_2b[b,k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
}#
#
for(k in 1:p)#
{	#
	error_1b[k] = mean(errors_1b[,k])#
	error_2b[k] = mean(errors_2b[,k])#
}#
#
err.bag_1[m,] = error_1b#
err.bag_2[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e.b_1[k] = mean(err.bag_1[,k])#
	e.b_2[k] = mean(err.bag_2[,k])#
}#
#
# e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)#
#
# e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)#
#
# e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)#
#
# e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)#
#
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
?regsubsets
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
errors_1 = rep(0, p)#
errors_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	errors_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	errors_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = errors_1#
err_2[m,] = errors_2
pred_1
errors_1
errors_2
?array
B = 50#
errors_1b = matrix(ncol = p, nrow = B, 0)#
errors_2b = matrix(ncol = p, nrow = B, 0)#
pred_1 = array(NA, c(n, p, B))#
pred_2 = array(NA, c(n, p, B))#
error_1b = rep(0, p)#
error_2b = rep(0, p)#
#
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
	model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	# pred_1 = matrix(ncol = p, nrow = n, 0)#
	# pred_2 = matrix(ncol = p, nrow = n, 0)#
	for(k in 1:p)#
	{#
		pred_1[,k,b] = predict(model_1, X_Test, id=k)#
		pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		errors_1b[b,k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		errors_2b[b,k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
}
B = 50#
errors_1b = matrix(ncol = p, nrow = B, 0)#
errors_2b = matrix(ncol = p, nrow = B, 0)#
pred_1 = array(NA, c(n, p, B))#
pred_2 = array(NA, c(n, p, B))#
error_1b = rep(0, p)#
error_2b = rep(0, p)#
#
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
	model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	# pred_1 = matrix(ncol = p, nrow = n, 0)#
	# pred_2 = matrix(ncol = p, nrow = n, 0)#
	for(k in 1:p)#
	{#
		pred_1[,k,b] = predict(model_1, X_Test, id=k)#
		pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		errors_1b[b,k] = apply((pred_1[,k,b]-Y_Test_1)^2, 2, mean)#
		errors_2b[b,k] = apply((pred_2[,k,b]-Y_Test_2)^2, 2, mean)#
	}#
}
pr_1[m,k] = mean(pred_1[m,k,])
pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
pr_2 = matrix(ncol = p, nrow = n, NA)
pr_1[m,k] = mean(pred_1[m,k,])
pr_1
B = 50	#
errors_1b = matrix(ncol = p, nrow = B, NA)		# error matrices of all bootstrap samples#
errors_2b = matrix(ncol = p, nrow = B, NA)#
error_1b = rep(NA, p) 							# bagged errors#
error_2b = rep(NA, p)#
#
pred_1 = array(NA, c(n, p, B)) 					# predicted values array for all bootstrap samples#
pred_2 = array(NA, c(n, p, B))#
pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
pr_2 = matrix(ncol = p, nrow = n, NA) #
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
	model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	for(k in 1:p)#
	{#
		pred_1[,k,b] = predict(model_1, X_Test, id=k)#
		pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		# errors_1b[b,k] = apply((pred_1[,k,b]-Y_Test_1)^2, 2, mean)#
		# errors_2b[b,k] = apply((pred_2[,k,b]-Y_Test_2)^2, 2, mean)#
	}#
}#
#
for(k in 1:p)#
{	#
	for(m in 1:n)#
	{#
		pr_1[m,k] = mean(pred_1[m,k,])#
		pr_2[m,k] = mean(pred_2[m,k,])#
	}#
	error_1b[k] = mean((pr_1[,k]-Y_Test_1)^2)#
	error_2b[k] = mean((pr_2[,k]-Y_Test_2)^2)#
}
error_1b
error_2b
error_1
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
errors_1 = rep(0, p)#
errors_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	errors_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	errors_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = errors_1#
err_2[m,] = errors_2
errors_1
errors_2
#### STAT 239 HW 4#
#
#### DATA ANALYSIS I: BAGGING LINEAR PREDICTORS#
#
# 1)#
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 3#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, M, p)#
err_2 = matrix(NA, M, p)#
err.bag_1 = matrix(NA, M, p)#
err.bag_2 = matrix(NA, M, p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e.b_1 = rep(NA, p)#
e.b_2 = rep(NA, p)#
#
for(m in 1:M)#
{#
#
X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
#
Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
#
Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
#
# signal to noise ratio#
s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
#
# 2)#
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
errors_1 = rep(0, p)#
errors_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	errors_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	errors_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = errors_1#
err_2[m,] = errors_2#
# 3, 4, 5)#
B = 50	#
errors_1b = matrix(ncol = p, nrow = B, NA)		# error matrices of all bootstrap samples#
errors_2b = matrix(ncol = p, nrow = B, NA)#
error_1b = rep(NA, p) 							# bagged errors#
error_2b = rep(NA, p)#
#
pred_1 = array(NA, c(n, p, B)) 					# predicted values array for all bootstrap samples#
pred_2 = array(NA, c(n, p, B))#
pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
pr_2 = matrix(ncol = p, nrow = n, NA) #
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
	model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	for(k in 1:p)#
	{#
		pred_1[,k,b] = predict(model_1, X_Test, id=k)#
		pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		# errors_1b[b,k] = apply((pred_1[,k,b]-Y_Test_1)^2, 2, mean)#
		# errors_2b[b,k] = apply((pred_2[,k,b]-Y_Test_2)^2, 2, mean)#
	}#
}#
#
for(k in 1:p)#
{	#
	for(m in 1:n)#
	{#
		pr_1[m,k] = mean(pred_1[m,k,])#
		pr_2[m,k] = mean(pred_2[m,k,])#
	}#
	error_1b[k] = mean((pr_1[,k]-Y_Test_1)^2)#
	error_2b[k] = mean((pr_2[,k]-Y_Test_2)^2)#
}#
#
err.bag_1[m,] = error_1b#
err.bag_2[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e.b_1[k] = mean(err.bag_1[,k])#
	e.b_2[k] = mean(err.bag_2[,k])#
}#
#
# e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)#
#
# e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)#
#
# e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)#
#
# e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)#
#
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
e_1
e_2
e.b_1
e.b_2
error_1
err_1
errors_1
error_1b
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
#
error_1 = rep(0, p)#
error_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	error_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	error_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = error_1#
err_2[m,] = error_2
err_1
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 3#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, M, p)#
err_2 = matrix(NA, M, p)#
err_1b = matrix(NA, M, p)#
err_2b = matrix(NA, M, p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e_1b = rep(NA, p)#
e_2b = rep(NA, p)#
#
for(m in 1:M)#
{#
#
X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
#
Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
#
Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
#
# signal to noise ratio#
s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
#
# 2)#
model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
#
pred_1 = matrix(ncol = p, nrow = n, 0)#
pred_2 = matrix(ncol = p, nrow = n, 0)#
#
error_1 = rep(0, p)#
error_2 = rep(0, p)#
#
for(k in 1:p)#
{#
	pred_1[,k] = predict(model_1, X_Test, id=k)#
	pred_2[,k] = predict(model_2, X_Test, id=k)#
	error_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
	error_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
}#
err_1[m,] = error_1#
err_2[m,] = error_2#
# 3, 4, 5)#
B = 50	#
error_1b = rep(NA, p) 							# bagged errors#
error_2b = rep(NA, p)#
#
pred_1 = array(NA, c(n, p, B)) 					# predicted values array for all bootstrap samples#
pred_2 = array(NA, c(n, p, B))#
pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
pr_2 = matrix(ncol = p, nrow = n, NA) #
for(b in 1:B)#
{#
	bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
	model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
	model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
	for(k in 1:p)#
	{#
		pred_1[,k,b] = predict(model_1, X_Test, id=k)#
		pred_2[,k,b] = predict(model_2, X_Test, id=k)#
	}#
}#
#
for(k in 1:p)#
{	#
	for(m in 1:n)#
	{#
		pr_1[m,k] = mean(pred_1[m,k,])#
		pr_2[m,k] = mean(pred_2[m,k,])#
	}#
	error_1b[k] = mean((pr_1[,k]-Y_Test_1)^2)#
	error_2b[k] = mean((pr_2[,k]-Y_Test_2)^2)#
}#
#
err_1b[m,] = error_1b#
err_2b[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e_1b[k] = mean(err_1b[,k])#
	e_2b[k] = mean(err_2b[,k])#
}
error_1b
error_1
err_1
err_1b
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 1#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, M, p)#
err_2 = matrix(NA, M, p)#
err_1b = matrix(NA, M, p)#
err_2b = matrix(NA, M, p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e_1b = rep(NA, p)#
e_2b = rep(NA, p)#
#
for(m in 1:M)#
{#
	X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
	Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
	Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
	Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
	# signal to noise ratio#
	s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
	s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
	# 2)#
	model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
	model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	error_1 = rep(0, p)#
	error_2 = rep(0, p)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		error_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		error_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
	err_1[m,] = error_1#
	err_2[m,] = error_2#
	# 3, 4, 5)#
	B = 50	#
	error_1b = rep(NA, p) 							# bagged errors#
	error_2b = rep(NA, p)#
	pred_1 = array(NA, c(n, p, B)) 					# predicted values array for all bootstrap samples#
	pred_2 = array(NA, c(n, p, B))#
	pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
	pr_2 = matrix(ncol = p, nrow = n, NA) #
	for(b in 1:B)#
	{#
		bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
		model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
		model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
		for(k in 1:p)#
		{#
			pred_1[,k,b] = predict(model_1, X_Test, id=k)#
			pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		}#
	}#
	for(k in 1:p)#
	{	#
		for(m in 1:n)#
		{#
			pr_1[m,k] = mean(pred_1[m,k,])#
			pr_2[m,k] = mean(pred_2[m,k,])#
		}#
		error_1b[k] = mean((pr_1[,k]-Y_Test_1)^2)#
		error_2b[k] = mean((pr_2[,k]-Y_Test_2)^2)#
	}#
	err_1b[m,] = error_1b#
	err_2b[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e_1b[k] = mean(err_1b[,k])#
	e_2b[k] = mean(err_2b[,k])#
}
err_1
err_1b
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 1#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, nrow=M, ncol=p)#
err_2 = matrix(NA, nrow=M, ncol=p)#
err_1b = matrix(NA, nrow=M, ncol=p)#
err_2b = matrix(NA, nrow=M, ncol=p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e_1b = rep(NA, p)#
e_2b = rep(NA, p)#
#
for(m in 1:M)#
{#
	X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
	Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
	Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
	Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
	# signal to noise ratio#
	s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
	s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
	# 2)#
	model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
	model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	error_1 = rep(0, p)#
	error_2 = rep(0, p)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		error_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		error_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
	err_1[m,] = error_1#
	err_2[m,] = error_2#
	# 3, 4, 5)#
	B = 50	#
	error_1b = rep(NA, p) 							# bagged errors#
	error_2b = rep(NA, p)#
	pred_1 = array(NA, c(n, p, B)) 					# predicted values array for all bootstrap samples#
	pred_2 = array(NA, c(n, p, B))#
	pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
	pr_2 = matrix(ncol = p, nrow = n, NA) #
	for(b in 1:B)#
	{#
		bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
		model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
		model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
		for(k in 1:p)#
		{#
			pred_1[,k,b] = predict(model_1, X_Test, id=k)#
			pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		}#
	}#
	for(k in 1:p)#
	{	#
		for(d in 1:n)#
		{#
			pr_1[d,k] = mean(pred_1[d,k,])#
			pr_2[d,k] = mean(pred_2[d,k,])#
		}#
		error_1b[k] = mean((pr_1[,k]-Y_Test_1)^2)#
		error_2b[k] = mean((pr_2[,k]-Y_Test_2)^2)#
	}#
	err_1b[m,] = error_1b#
	err_2b[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e_1b[k] = mean(err_1b[,k])#
	e_2b[k] = mean(err_2b[,k])#
}
e_1
e_1b
#### STAT 239 HW 4#
#
#### DATA ANALYSIS I: BAGGING LINEAR PREDICTORS#
#
# 1)#
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 10#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, nrow=M, ncol=p)#
err_2 = matrix(NA, nrow=M, ncol=p)#
err_1b = matrix(NA, nrow=M, ncol=p)#
err_2b = matrix(NA, nrow=M, ncol=p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e_1b = rep(NA, p)#
e_2b = rep(NA, p)#
#
for(m in 1:M)#
{#
	X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
	Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
	Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
	Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
	# signal to noise ratio#
	s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
	s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
	# 2)#
	model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
	model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	error_1 = rep(0, p)#
	error_2 = rep(0, p)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		error_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		error_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
	err_1[m,] = error_1#
	err_2[m,] = error_2#
	# 3, 4, 5)#
	B = 50	#
	error_1b = rep(NA, p) 							# bagged errors#
	error_2b = rep(NA, p)#
	pred_1 = array(NA, c(n, p, B)) 					# predicted values array for all bootstrap samples#
	pred_2 = array(NA, c(n, p, B))#
	pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
	pr_2 = matrix(ncol = p, nrow = n, NA) #
	for(b in 1:B)#
	{#
		bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
		model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
		model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
		for(k in 1:p)#
		{#
			pred_1[,k,b] = predict(model_1, X_Test, id=k)#
			pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		}#
	}#
	for(k in 1:p)#
	{	#
		for(d in 1:n)#
		{#
			pr_1[d,k] = mean(pred_1[d,k,])#
			pr_2[d,k] = mean(pred_2[d,k,])#
		}#
		error_1b[k] = mean((pr_1[,k]-Y_Test_1)^2)#
		error_2b[k] = mean((pr_2[,k]-Y_Test_2)^2)#
	}#
	err_1b[m,] = error_1b#
	err_2b[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e_1b[k] = mean(err_1b[,k])#
	e_2b[k] = mean(err_2b[,k])#
}#
#
# e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)#
#
# e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)#
#
# e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)#
#
# e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)#
#
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e.b_1, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e.b_2, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
e_1
e_1b
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e_1b, type="l")#
text(x=25, e_1[25], labels="not bagged")#
text(x=25, e.b_1[25], labels="bagged")#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e_2b, type="l")#
text(x=25, e_2[25], labels="not bagged")#
text(x=25, e.b_2[25], labels="bagged")#
#
dev.off()
lines(e_1b, type="l", col="red")
?par
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e_1b, type="l", col="blue")#
legend(x=0, y=10, legend=c("bagged", "not bagged"), col=c("blue", "black"))#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e_2b, type="l", col="blue")#
legend(x=0, y=100, legend=c("bagged", "not bagged"), col=c("blue", "black"))#
#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e_1b, type="l", col="blue")#
legend(x=0, y=10, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e_2b, type="l", col="blue")#
legend(x=0, y=100, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e_1b, type="l", col="blue")#
legend(x=25, y=12, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e_2b, type="l", col="blue")#
legend(x=25, y=60, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e_1b, type="l", col="blue")#
legend(x=20, y=12, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e_2b, type="l", col="blue")#
legend(x=20, y=60, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
dev.off()
#### STAT 239 HW 4#
#
#### DATA ANALYSIS I: BAGGING LINEAR PREDICTORS#
#
# 1)#
library(MASS)#
library(leaps)#
#
n = 60#
p = 30#
rho = 0.4#
#
betaZero_1 = 3.6#
beta_1 = c(round(rnorm(5, 0, 2), 2), rep(0, 25))#
 # [1]  1.90  2.27 -4.27  1.85 -2.40  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [13]  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00#
# [25]  0.00  0.00  0.00  0.00  0.00  0.00#
#
betaZero_2 = -2.3#
beta_2 = c(round(rnorm(25, 0, 2), 2), rep(0, 5))#
 # [1]  0.48 -2.16  0.77 -0.23  0.50 -2.19 -0.77  1.94  1.21  0.48  1.20 -2.09#
# [13]  0.29 -0.87  1.35 -2.62 -1.48 -1.75 -1.15 -2.74  0.19 -4.59 -0.61  0.36#
# [25] -0.33  0.00  0.00  0.00  0.00  0.00#
#
sigma = matrix(ncol = p, nrow = p, 0)#
for(i in 1:p)#
{#
	for(j in 1:i)#
	{#
		sigma[i, j] = rho^{abs(i-j)}#
		sigma[j, i] = sigma[i, j]#
	}#
}#
#
predict.regsubsets = function(object, newdata , id) #
{#
	if(object$nvmax <= id) {print(object$nvmax);  return(NA)}#
	p = ncol(newdata)#
	mat = cbind(rep(1, nrow(newdata)), newdata)#
	colnames(mat) = c("(Intercept)", 1:p)#
	coeffic = coef(summary(object)$obj, id=id)#
	xvars = names(coeffic)#
	mat[ , xvars]%*% coeffic#
}#
#
M = 300#
s1 = rep(NA, M)#
s2 = rep(NA, M)#
#
err_1 = matrix(NA, nrow=M, ncol=p)#
err_2 = matrix(NA, nrow=M, ncol=p)#
err_1b = matrix(NA, nrow=M, ncol=p)#
err_2b = matrix(NA, nrow=M, ncol=p)#
#
e_1 = rep(NA, p)#
e_2 = rep(NA, p)#
e_1b = rep(NA, p)#
e_2b = rep(NA, p)#
#
for(m in 1:M)#
{#
	X_Train = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	X_Test = mvrnorm(n = 60, mu = rep(0, p), sigma)#
	Y_Train_1 = betaZero_1 + X_Train %*% beta_1 + rnorm(n, 0, 1)#
	Y_Train_2 = betaZero_2 + X_Train %*% beta_2 + rnorm(n, 0, 1)#
	Y_Test_1 = betaZero_1 + X_Test %*% beta_1 + rnorm(n, 0, 1)#
	Y_Test_2 = betaZero_2 + X_Test %*% beta_2 + rnorm(n, 0, 1)#
	# signal to noise ratio#
	s1[m] = t(beta_1) %*% cov(X_Train) %*% beta_1#
	s2[m] = t(beta_2) %*% cov(X_Train) %*% beta_2#
	# 2)#
	model_1 = regsubsets(x = X_Train, y = Y_Train_1, method = "forward", nvmax = p)#
	model_2 = regsubsets(x = X_Train, y = Y_Train_2, method = "forward", nvmax = p)#
	pred_1 = matrix(ncol = p, nrow = n, 0)#
	pred_2 = matrix(ncol = p, nrow = n, 0)#
	error_1 = rep(0, p)#
	error_2 = rep(0, p)#
	for(k in 1:p)#
	{#
		pred_1[,k] = predict(model_1, X_Test, id=k)#
		pred_2[,k] = predict(model_2, X_Test, id=k)#
		error_1[k] = apply((pred_1[,k]-Y_Test_1)^2, 2, mean)#
		error_2[k] = apply((pred_2[,k]-Y_Test_2)^2, 2, mean)#
	}#
	err_1[m,] = error_1#
	err_2[m,] = error_2#
	# 3, 4, 5)#
	B = 50	#
	error_1b = rep(NA, p) 							# bagged errors#
	error_2b = rep(NA, p)#
	pred_1 = array(NA, c(n, p, B)) 					# predicted values array for all bootstrap samples#
	pred_2 = array(NA, c(n, p, B))#
	pr_1 = matrix(ncol = p, nrow = n, NA) 			# bagged predicted values#
	pr_2 = matrix(ncol = p, nrow = n, NA) #
	for(b in 1:B)#
	{#
		bootstraps = sample(nrow(X_Train), nrow(X_Train), replace=TRUE)#
		model_1 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_1[bootstraps], method="forward", nvmax=p)#
		model_2 = regsubsets(x=X_Train[bootstraps,], y=Y_Train_2[bootstraps], method="forward", nvmax=p)#
		for(k in 1:p)#
		{#
			pred_1[,k,b] = predict(model_1, X_Test, id=k)#
			pred_2[,k,b] = predict(model_2, X_Test, id=k)#
		}#
	}#
	for(k in 1:p)#
	{	#
		for(d in 1:n)#
		{#
			pr_1[d,k] = mean(pred_1[d,k,])#
			pr_2[d,k] = mean(pred_2[d,k,])#
		}#
		error_1b[k] = mean((pr_1[,k]-Y_Test_1)^2)#
		error_2b[k] = mean((pr_2[,k]-Y_Test_2)^2)#
	}#
	err_1b[m,] = error_1b#
	err_2b[m,] = error_2b#
#
}#
#
for(k in 1:p)#
{	#
	e_1[k] = mean(err_1[,k])#
	e_2[k] = mean(err_2[,k])#
	e_1b[k] = mean(err_1b[,k])#
	e_2b[k] = mean(err_2b[,k])#
}#
#
# e_1 =  c(12.639854,  6.633281,  3.348427,  2.044545,  1.113499,  1.217414,  1.301690, 1.371579,  1.435692,  1.495408,  1.547937,  1.596609,  1.650130,  1.700059, 1.749338,  1.797179,  1.838497,  1.881290,  1.920973,  1.955166,  1.987184, 2.010237,  2.031910,  2.057306,  2.074305,  2.089768,  2.100970,  2.106613, 2.107773,  2.108921)#
#
# e_2 = c(106.980693,  84.547473,  68.733621,  57.816671,  48.268692,  40.275858, 32.798007,  26.354124,  21.078976,  17.311173,  14.734531,  12.558604, 10.465431,   8.685150,   7.184045,   5.875920,   4.821630,   4.008683, 3.323948,   2.733083,   2.308431,   2.046559,   1.974705,   1.997558, 2.007143,   2.043383,   2.068426,   2.079028,   2.089448,   2.092109)#
#
# e.b_1 = c(13.312782,  7.477038,  4.030492,  2.419446,  1.408987,  1.511981,  1.645889, 1.779386,  1.911361,  2.044177,  2.177750, 2.316536,  2.455464,  2.606335,  2.765053,  2.937391,  3.118371,  3.316503,  3.529003,  3.756344,  4.005605, 4.272132,  4.584165,  4.916661,  5.271447,  5.679287,  6.178899,        NA,  NA,        NA)#
#
# e.b_2 = c(117.153899,  98.961800,  84.318931,  73.400799,  64.005110,  56.055786, 49.062315,  42.680075,  37.109575,  32.459834,  28.442248,  24.992009, 21.975951,  19.316447,  16.950197,  14.841454,  13.023366,  11.467491, 10.100312,   8.928099,   7.965962,   7.227064,   6.676803,   6.308238, 6.131309,   6.119488,   6.299565,         NA,         NA,         NA)#
#
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e_1b, type="l", col="blue")#
legend(x=20, y=12, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e_2b, type="l", col="blue")#
legend(x=20, y=60, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
dev.off()
pdf("plots.pdf")#
#
plot(e_1, type="l", xlab="# predictors in model", main="5 nonzero coefficients", ylab="test error")#
lines(e_1b, type="l", col="blue")#
legend(x=20, y=9, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
plot(e_2, type="l", xlab="# predictors in model", main="25 nonzero coefficients", ylab="test error")#
lines(e_2b, type="l", col="blue")#
legend(x=20, y=60, legend=c("bagged", "not bagged"), col=c("blue", "black"), lty=1)#
#
dev.off()
e_1
e_2
e_1b
e_2b
